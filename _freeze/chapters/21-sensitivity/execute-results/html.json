{
  "hash": "a523c045ba3a4e5291f4768f0bfab21b",
  "result": {
    "markdown": "# Sensitivity analysis  {#sec-sensitivity}\n\n\n\n\n\n\n\n\nBecause many of the assumptions of causal inference are unverifiable, it's reasonable to be concerned about the validity of your results. In this chapter, we'll provide some ways to probe our assumptions and results for strengths and weaknesses. We'll explore two main ways to do so: exploring the logical implications of the causal question and related DAGs and using mathematical techniques to quantify how different our results would be under other circumstances, such as in the presence of unmeasured confounding. These techniques are known as *sensitivity analyses*: how sensitive is our result to other conditions than laid out in our assumptions and analysis?\n\n## Checking DAGs for robustness\n\nLet's start with where we started the modeling process: creating causal diagrams. Because DAGs encode the assumptions we're basing our analysis on, they are a natural point of critique from both others and ourselves.\n\n### Alternate adjustment sets and alternate DAGs\n\nThe same mathematical underpinnings of DAGs that allow us to to query them for things like adjustment sets also allow us to query other implications of DAGs. One of the simplest is that, if your DAG is right and your data are well-measured, any valid adjustment set should result in an unbiased estimate of the causal effect. Let's consider the DAG we introduced in @sec-TODO.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIn this DAG, there's only one adjustment set because all three confounders represent independent backdoor paths. Let's say, though, that we had used this DAG instead, which is missing an arrow from park close time to whether or not there was an extra magic morning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemm_wait_dag_missing <- dagify(\n  wait_minutes_posted_avg ~ park_extra_magic_morning + park_close + park_ticket_season + park_temperature_high,\n  park_extra_magic_morning ~ park_ticket_season,\n  coords = coord_dag,\n  labels = labels,\n  exposure = \"park_extra_magic_morning\",\n  outcome = \"wait_minutes_posted_avg\"\n)\n\nadj_sets <- unclass(dagitty::adjustmentSets(emm_wait_dag_missing, type = \"all\")) |> \n  map_chr(\\(.x) glue::glue('{unlist(glue::glue_collapse(.x, sep = \" + \"))}')) |> \n  glue::glue_collapse(sep = \", \", last = \", or \")\n\nemm_wait_dag_missing |>\n  tidy_dagitty() |>\n  node_status() |>\n  ggplot(\n    aes(x, y, xend = xend, yend = yend, color = status)\n  ) +\n  geom_dag_edges_arc(curvature = c(rep(0, 2), .3, rep(0, 2))) +\n  geom_dag_point() +\n  geom_dag_label_repel(seed = 1630) +\n  scale_color_okabe_ito(na.value = \"grey90\") +\n  theme_dag() +\n  theme(\n    legend.position = \"none\",\n    axis.text.x = element_text()\n  ) +\n  coord_cartesian(clip = \"off\") +\n  scale_x_continuous(\n    limits = c(-1.25, 2.25),\n    breaks = c(-1, 0, 1, 2),\n    labels = c(\n      \"\\n(one year ago)\",\n      \"\\n(6 months ago)\",\n      \"\\n(3 months ago)\",\n      \"9am - 10am\\n(Today)\"\n    )\n  )\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nNow there are 4 potential adjustment sets: park_ticket_season, park_close + park_ticket_season, park_temperature_high + park_ticket_season, or park_close + park_temperature_high + park_ticket_season. @tbl-alt-sets presents the IPW estimates for each adjustment set. The effects are quite different. Some small variation in the estimates is expected since they are estimated using different variables, if this DAG were right, we should see them much more closely aligned than this. In particular, it seems that there is about a 3 minute difference in the models with and without park close time.\n\n\n::: {#tbl-alt-sets .cell tbl-cap='TODO. Sorted'}\n\n```{.r .cell-code}\nseven_dwarfs <- touringplans::seven_dwarfs_train_2018 |>\n  filter(wait_hour == 9)\n\n# we'll use `.data` and `.trt` later\nfit_ipw_effect <- function(.fmla, .data = seven_dwarfs, .trt = \"park_extra_magic_morning\", .outcome_fmla = wait_minutes_posted_avg ~ park_extra_magic_morning) {\n  .trt_var <- rlang::ensym(.trt)\n  \n  # fit propensity score model\n  propensity_model <- glm(\n    .fmla,\n    data = .data,\n    family = binomial()\n  )\n  \n  # calculate ATE weights\n  .df <- propensity_model |>\n    augment(type.predict = \"response\", data = .data) |> \n    mutate(w_ate = wt_ate(.fitted, !!.trt_var, exposure_type = \"binary\"))\n\n  # fit correctly bootstrapped ipw model \n  lm(.outcome_fmla, data = .df, weights = w_ate) |>\n    tidy() |> \n    filter(term == .trt) |> \n    pull(estimate)\n}\n\neffects <- list(\n  park_extra_magic_morning ~ park_ticket_season,\n  park_extra_magic_morning ~ park_close + park_ticket_season,\n  park_extra_magic_morning ~ park_temperature_high + park_ticket_season,\n  park_extra_magic_morning ~ park_temperature_high +\n    park_close + park_ticket_season\n) |> \n  map_dbl(fit_ipw_effect)\n\ntibble(\n  `Adjustment Set` = c(\n    \"Ticket season\",\n    \"Close time, ticket season\",\n    \"Historic temperature, ticket season\",\n    \"Historic temperature, close time, ticket season\"\n  ),\n  ATE = effects\n) |> \n  arrange(ATE) |> \n  gt()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"wzertbatxm\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#wzertbatxm table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#wzertbatxm thead, #wzertbatxm tbody, #wzertbatxm tfoot, #wzertbatxm tr, #wzertbatxm td, #wzertbatxm th {\n  border-style: none;\n}\n\n#wzertbatxm p {\n  margin: 0;\n  padding: 0;\n}\n\n#wzertbatxm .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#wzertbatxm .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wzertbatxm .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wzertbatxm .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wzertbatxm .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wzertbatxm .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wzertbatxm .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wzertbatxm .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wzertbatxm .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#wzertbatxm .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#wzertbatxm .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wzertbatxm .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wzertbatxm .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wzertbatxm .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wzertbatxm .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzertbatxm .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#wzertbatxm .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#wzertbatxm .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#wzertbatxm .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzertbatxm .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#wzertbatxm .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzertbatxm .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wzertbatxm .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzertbatxm .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wzertbatxm .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wzertbatxm .gt_left {\n  text-align: left;\n}\n\n#wzertbatxm .gt_center {\n  text-align: center;\n}\n\n#wzertbatxm .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wzertbatxm .gt_font_normal {\n  font-weight: normal;\n}\n\n#wzertbatxm .gt_font_bold {\n  font-weight: bold;\n}\n\n#wzertbatxm .gt_font_italic {\n  font-style: italic;\n}\n\n#wzertbatxm .gt_super {\n  font-size: 65%;\n}\n\n#wzertbatxm .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#wzertbatxm .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#wzertbatxm .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#wzertbatxm .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#wzertbatxm .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#wzertbatxm .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#wzertbatxm .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Adjustment Set\">Adjustment Set</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"ATE\">ATE</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"Adjustment Set\" class=\"gt_row gt_left\">Historic temperature, ticket season</td>\n<td headers=\"ATE\" class=\"gt_row gt_right\">3.627</td></tr>\n    <tr><td headers=\"Adjustment Set\" class=\"gt_row gt_left\">Ticket season</td>\n<td headers=\"ATE\" class=\"gt_row gt_right\">4.114</td></tr>\n    <tr><td headers=\"Adjustment Set\" class=\"gt_row gt_left\">Historic temperature, close time, ticket season</td>\n<td headers=\"ATE\" class=\"gt_row gt_right\">6.199</td></tr>\n    <tr><td headers=\"Adjustment Set\" class=\"gt_row gt_left\">Close time, ticket season</td>\n<td headers=\"ATE\" class=\"gt_row gt_right\">6.579</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n### Negative controls\n\nAlternate adjustment sets are a way of probing the logical implications of your DAG: if it's correct, there should then be may ways to correctly account for the open backdoor paths. The reverse is also true: the causal structure of your research question also implies relationships that, if you are correct, should be *null*. One way that researchers take advantage of this implication is through *negative controls*. A negative control is either an exposure (negative exposure control) or outcome (negative outcome control) which is similar to your question in as many ways as possible except that there *shouldn't* be a causal effect. @TODO describe negative controls for observational research. In their article, they reference common controls in bench science:\n\n1. Leave out an essential ingredient. \n2. Inactivate the hypothesized active ingredient. \n3. Check for an effect that would be impossible by the hypothesized outcome. \n\nTo find a good negative control, you usually need to extend your DAG to include more of the causal structure surrounding your question. Let's look at some examples. \n\n#### Negative exposures\n\nFirst, we'll look at a negative exposure control. If extra magic mornings really do cause an increase in wait time, it stands to reason that this effect is time-limited. In other words, there should be some period of time after which the effect of extra magic morning dissipates. It's call today *i* and the previous day *i - d* where *j* is the number days previous the negative exposure is. First, let's explore `j = 63`, e.g. whether or not there was extra magic morning 9 weeks ago. That seems like a pretty reasonable starting point: it's exceedingly unlikely that the effect on wait time would still be present 63 days later. This is an example of leaving out an essential ingredient: we waited too long for this to be realistic. Any remaining effect is likely due to residual confounding. \n\nLet's look at a DAG visualizing this situation. In @fig-dag-day-i, we've essentially added an identical layer to our original one: now there are two extra magic mornings: one for day `i` and one for day `i - 63`. Similarly, there are two versions of the confounders for each day. One important detail in this DAG is that we're assuming that there *is* an effect of day `i - 63`'s extra magic morning on day `i`'s; whether or not there is an extra magic morning one day does likely effect whether or not they happen on another day. The decision about where to place them across the year is not random. If this is true, then we *would* expect an effect: the indirect effect via day `i`'s extra magic morning status. To get a true negative control, we need to *inactivate this effect*, which we can do statistically by controlling for it. So, given the DAG, our adjustment set is any combination of the confounders (as long as we have at least one version of each) and day `i`'s extra magic morning (suppressing the indirect effect).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlabels <- c(\n  x63 = \"Extra Magic Morning (i-63)\",\n  x = \"Extra Magic Morning (i)\",\n  y = \"Average wait\",\n  season = \"Ticket Season\",\n  weather = \"Historic high temperature\",\n  close = \"Time park closed (i)\",\n  season63 = \"Ticket Season (i-63)\",\n  weather63 = \"Historic high temperature (i-63)\",\n  close63 = \"Time park closed (i-63)\"\n)\n\ndagify(\n  y ~ x + close + season + weather,\n  x ~ weather + close + season + x63,\n  x63 ~ weather63 + close63 + season63,\n  weather ~ weather63,\n  close ~ close63, \n  season ~ season63,\n  coords = time_ordered_coords(),\n  labels = labels,\n  exposure = \"x63\",\n  outcome = \"y\"\n) |>\n  tidy_dagitty() |>\n  node_status() |>\n  ggplot(\n    aes(x, y, xend = xend, yend = yend, color = status)\n  ) +\n  geom_dag_edges_link() +\n  geom_dag_point() +\n  geom_dag_label_repel() +\n  scale_color_okabe_ito(na.value = \"grey90\") +\n  theme_dag() +\n  theme() +\n  coord_cartesian(clip = \"off\")\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/fig-dag-day-i-1.png){#fig-dag-day-i width=672}\n:::\n:::\n\n\nSince the exposure is on day `i - 63`, we prefer to control for the confounders related to that day, so we'll use the `i - 63` versions. To get those variables, we'll use `lag()` from dplyr. We're going to check other days, too, so let's write this as a function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalculate_coef <- function(n_days_lag) {\n  distinct_emm <- seven_dwarfs_train_2018 |> \n    filter(wait_hour == 9) |> \n    arrange(park_date) |> \n    transmute(\n      park_date, \n      prev_park_extra_magic_morning = lag(park_extra_magic_morning, n = n_days_lag),\n      prev_park_temperature_high = lag(park_temperature_high, n = n_days_lag),\n      prev_park_close = lag(park_close, n = n_days_lag),\n      prev_park_ticket_season = lag(park_ticket_season, n = n_days_lag)\n    )\n  \n  seven_dwarfs_train_2018_lag <- seven_dwarfs_train_2018 |> \n    filter(wait_hour == 9) |> \n    left_join(distinct_emm, by = \"park_date\") |> \n    filter(!is.na(prev_park_extra_magic_morning))\n  \n  fit_ipw_effect(\n    prev_park_extra_magic_morning ~ prev_park_temperature_high + prev_park_close + prev_park_ticket_season,\n    .data = seven_dwarfs_train_2018_lag, \n    .trt = \"prev_park_extra_magic_morning\",\n    .outcome_fmla = wait_minutes_posted_avg ~ prev_park_extra_magic_morning + park_extra_magic_morning\n  )\n}\n\ncalculate_coef(63)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.9285\n```\n\n\n:::\n:::\n\n\nWell, the effect is much closer to null than what we found on day `i`. Let's take a look at the effect over time. We suppose that, while there might be a lingering effect of extra magic mornings for a little while (say, the span of an average trip to Disney World), it should quickly approach null.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefs <- purrr::map_dbl(1:63, calculate_coef)\n\nggplot(data.frame(coefs = coefs, x = 1:63), aes(x = x, y = coefs)) + \n  geom_hline(yintercept = 0) + \n  geom_smooth() + \n  labs(y = \"difference in wait times (minutes)\\n on day (i) for EMM on day (i - n)\", x = \"day (i - n)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula =\n'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nIf you try this with lags going further in time, you'll see the residual association comes and goes apparently cyclically, although the estimate is less and less stable for every day's lag because of the sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefs <- purrr::map_dbl(1:200, calculate_coef)\n\nggplot(data.frame(coefs = coefs, x = 1:200), aes(x = x, y = coefs)) + \n  geom_hline(yintercept = 0) + \n  geom_smooth() + \n  labs(y = \"difference in wait times (minutes)\\n on day (i) for EMM on day (i - n)\", x = \"day (i - n)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using method = 'loess' and formula =\n'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nIf these results are accurate, it implies that we have some residual confounding in our effect. \n\n#### Negative outcomes\n\nNow, let's look at an example of a negative control outcome: the wait time at a ride in Universal Studios. Universal Studios is also in Orlando, and so the set of causes for wait times are likely comparable to those at Disney World on the same day. Of course, whether or not there are extra magic mornings at Disney shouldn't effect the wait times at Universal on the same day: they are separate parks, and presumably most people don't visit both within an hour of one another. This is an example of an effect that would be implausible by the hypothesized mechanism. \n\nWe don't have ride data for Universal, so let's simulate what would happen with and without residual confounding. We'll generate wait times that are based on the historic temperature, park close time, and ticket season (the second two are technically specific to Disney but we expect a strong correlation with the Universal versions). Because this is a negative outcome, it is not related to whether or not there were Extra Magic Morning hours at Disney.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseven_dwarfs_sim <- seven_dwarfs_train_2018 |> \n  mutate(\n    # we scale each variable and add a bit of random noise\n    # to simulate reasonable Universal wait times\n    wait_time_universal = \n      park_temperature_high / 150 + \n      as.numeric(park_close) / 1500 +\n      as.integer(factor(park_ticket_season)) / 1000 + \n      rnorm(n(), 5, 5)\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwait_universal <- seven_dwarfs_sim |> \n  fit_ipw_effect(\n    park_extra_magic_morning ~ park_temperature_high +\n      park_close + park_ticket_season,\n    .data = _,\n    .outcome_fmla = wait_time_universal ~ park_extra_magic_morning\n  ) |> round(2)\n```\n:::\n\n\nIf we calculate the IPW effect for `wait_time_universal`, we get 0.28, a roughly null effect, as expected. But what if we missed an unmeasured confounder, `u`, which was a cause of Extra Magic Mornings and wait times at both Disney and universal? Let's simulate that scenario but augmenting the data further.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseven_dwarfs_sim2 <- seven_dwarfs_train_2018 |>\n  mutate(\n    u = rnorm(n(), mean = 10, sd = 3),\n    wait_minutes_posted_avg = wait_minutes_posted_avg + u,\n    park_extra_magic_morning = ifelse(u > 10, rbinom(1, 1, .1), park_extra_magic_morning),\n    wait_time_universal = \n      park_temperature_high / 150 + \n      as.numeric(park_close) / 1500 +\n      as.integer(factor(park_ticket_season)) / 1000 + \n      u + \n      rnorm(n(), 5, 5)\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndisney <- seven_dwarfs_sim2 |>\n  fit_ipw_effect(\n    park_extra_magic_morning ~ park_temperature_high +\n      park_close + park_ticket_season,\n    .data = _\n  ) |> round(2)\n\nuniversal <- seven_dwarfs_sim2 |>\n  fit_ipw_effect(\n    park_extra_magic_morning ~ park_temperature_high +\n      park_close + park_ticket_season,\n    .data = _,\n    .outcome_fmla = wait_time_universal ~ park_extra_magic_morning\n  ) |> round(2)\n```\n:::\n\n\nNow the effect for both Disney and Universal wait times is different. If we had seen -0.16 for the effect for Disney, we wouldn't necessarily know that we had a confounded result. However, since we know the wait times at Universal should be unrelated, it's suspicious that the result, -2.76, is not null. That is evidence that we have unmeasured confounding.\n\n### DAG-data consistency\n\nNegative controls make use of the logical implications of the causal structure you assume. We can extend that idea to the entire DAG: there are many implications of the ways, statistically, that different variables in the DAG should and should not be related to each other if the DAG is correct. Like with negative controls, we can check if variables that *should* be independent *are* independent in the data. Sometimes, the way that DAGs imply independence between variables is *conditional* on other variables. Thus, this technique is sometimes called *implied conditional independencies* Let's query our original DAG to find what the DAG says about the relationships among the variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquery_conditional_independence(emm_wait_dag) |>\n  unnest(conditioned_on)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  set   a                     b          conditioned_on\n  <chr> <chr>                 <chr>      <chr>         \n1 1     park_close            park_temp… <NA>          \n2 2     park_close            park_tick… <NA>          \n3 3     park_temperature_high park_tick… <NA>          \n```\n\n\n:::\n:::\n\n\nIn this DAG, there are three relationships that should be null: 1) `park_close` and `park_temperature_high` 2) `park_close` and `park_ticket_season` and 3) `park_temperature_high` and `park_ticket_season`. None of these relationships need to condition on another variable to achieve independence; in other words, they should be unconditionally independent from one another. We can use simple techniques like correlation and regression, as well as other statistical tests, to see if nullness holds for these relationships. Conditional independencies quickly grow in number in complex DAGs, and so dagitty implements a way to automate checks for DAG-data consistency given these implied nulls. dagitty specifically checks if the residuals of a given conditional relationship are correlated, which can be modeled automatically in a number of ways. We'll tell dagitty to calculate the residuals using non-linear models with `type = \"cis.loess\"`. Since we're working with correlations, the results should be around 0 if our DAG is right. As we see in @fig-conditional-ind, though, two of these relationships don't hold.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_conditional_independence(\n    emm_wait_dag,\n    data = touringplans::seven_dwarfs_train_2018 |>\n        mutate(\n            across(where(is.character), factor),\n            park_close = as.numeric(park_close),\n            month = lubridate::week(park_date)\n        ) |> as.data.frame(),\n    type = \"cis.loess\",\n    R = 200\n) |>\n  ggdag_conditional_independence()\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/fig-conditional-ind-1.png){#fig-conditional-ind width=672}\n:::\n:::\n\n\nWhy might we be seeing a relationship when there isn't supposed to be one? A simple explanation is chance: just like in any type of statistical inference, we need to be cautious about over-extrapolating what we see in the limited sample we have. Since we have data for every day in 2018, though, we could probably rule that out. Another reason is that we're missing direct arrows from one variable to the other, e.g. from historic temperature to park close time. This is pretty reasonable: close time and ticket season both closely track the weather. That's a little bit of evidence that we're missing an arrow.\n\nAt this point, we need to be cautious about overfitting the DAG to the data. DAG-data consistency tests *cannot* prove your DAG right and wrong, and as we saw in @sec-quartets, statistical techniques alone cannot determine the causal structure of a problem. So why use these tests? As with negative controls, they provide a way to probe your assumptions. While we can never be sure about them, we *do* have information in the data. Finding that conditional independencies hold is a little more evidence in support of your assumptions. There's a fine line here, so we recommend being transparent about these types of checks: if you make changes based on the results of these tests, you should report your original DAG, too.\n\nNotably, in this case, adding direct arrows to all three of these relationships results in an identical adjustment set. That's an important detail! Sometimes we have the option to use an adjustment set that works for more than one DAG. This is good news for DAG-data consistency checks, because we have a related problem: different DAGs can have the same set of conditional independencies. \n\nIn our DAG, for instance, there are actually two DAGs which can generate the same implied conditional independencies (@fig-equiv-dag).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggdag_equivalent_dags(\n  emm_wait_dag, use_labels = \n    TRUE, \n  use_text = FALSE, \n  edge_type = \"arc\"\n)\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/fig-equiv-dag-1.png){#fig-equiv-dag width=672}\n:::\n:::\n\n\nLet's take a look at a more extreme example, where we remove the arrows from park close time and historic temperature to Extra Magic Morning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemm_wait_dag2 <- dagify(\n  wait_minutes_posted_avg ~ park_extra_magic_morning + park_close + park_ticket_season + park_temperature_high,\n  park_extra_magic_morning ~ park_ticket_season,\n  coords = coord_dag,\n  labels = labels,\n  exposure = \"park_extra_magic_morning\",\n  outcome = \"wait_minutes_posted_avg\"\n)\n\nquery_conditional_independence(emm_wait_dag2) |>\n  unnest(conditioned_on)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 4\n  set   a                        b       conditioned_on\n  <chr> <chr>                    <chr>   <chr>         \n1 1     park_close               park_e… <NA>          \n2 2     park_close               park_t… <NA>          \n3 3     park_close               park_t… <NA>          \n4 4     park_extra_magic_morning park_t… <NA>          \n5 5     park_temperature_high    park_t… <NA>          \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_conditional_independence(\n  emm_wait_dag2,\n  data = touringplans::seven_dwarfs_train_2018 |>\n    mutate(\n      across(where(is.character), factor),\n      park_close = as.numeric(park_close)\n    ) |> as.data.frame(),\n  type = \"cis.loess\",\n  R = 200\n) |>\n  ggdag_conditional_independence()\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggdag_equivalent_dags(emm_wait_dag2)\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggdag_equivalent_class(emm_wait_dag2)\n```\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# no overlapping sets\ndagitty::equivalenceClass(emm_wait_dag) |>\n  dagitty::adjustmentSets(type = \"all\")\n\ndags <- dagitty::equivalentDAGs(emm_wait_dag)\n\n# no overlapping sets\n# however, the reversable edge is season -> emm. This is implausible\ndags[[1]] |> dagitty::adjustmentSets(type = \"all\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{ park_close, park_temperature_high,\n  park_ticket_season }\n```\n\n\n:::\n\n```{.r .cell-code}\ndags[[2]] |> dagitty::adjustmentSets(type = \"all\")\n```\n:::\n\n\n\n### Alternate DAGs\n\n<!-- TODO: I think this should be an extension of what we do in the machine learning chapter, e.g. we throw a more complex set of covariates at TMLE then we revisit that analysis here. In other words, this alt dag should have a little bit of a thread through the book. -->\n\nAs we mentioned in @sec-dags-iterate, you should ideally specify your DAG ahead of time with ample feedback from other experts. Let's now go on the opposite direction as the last example: what if we used the original DAG but, after the analysis, receive feedback that we should add more variables? Consider this expanded DAG in @fig-dag-extra-days. We've added two new confounders: whether it's a weekend and whether it's a holiday. This is different than when we checked alternate adjustment sets in the same DAG; in that case, we're checking the logical consistency of the DAG. In this case, we're considering a different causal structure altogether. \n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 2 rows containing missing values or values\noutside the scale range (`geom_label_repel()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](21-sensitivity_files/figure-html/fig-dag-extra-days-1.png){#fig-dag-extra-days width=672}\n:::\n:::\n\n\nWe can calculate both of these features from `park_date` using the timeDate package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(timeDate)\n\nholidays <- c(\n  \"USChristmasDay\", \"USColumbusDay\", \"USIndependenceDay\", \n  \"USLaborDay\", \"USLincolnsBirthday\", \"USMemorialDay\", \n  \"USMLKingsBirthday\", \"USNewYearsDay\", \"USPresidentsDay\", \n  \"USThanksgivingDay\", \"USVeteransDay\", \"USWashingtonsBirthday\"\n) |> \n  holiday(2018, Holiday = _) |> \n  as.Date()\n\nseven_dwarfs_with_days <- seven_dwarfs_train_2018 |> \n  mutate(\n    is_holiday = park_date %in% holidays, \n    is_weekend = isWeekend(park_date)\n  ) |> \n  filter(wait_hour == 9)\n```\n:::\n\n\nBoth extra magic morning hours and posted wait times are associated with whether it's a holiday or weekend.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# TODO: hide the code and make a table or plot?\nseven_dwarfs_with_days |> \n  count(is_holiday, park_extra_magic_morning)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  is_holiday park_extra_magic_morning     n\n  <lgl>                         <dbl> <int>\n1 FALSE                             0   284\n2 FALSE                             1    59\n3 TRUE                              0    10\n4 TRUE                              1     1\n```\n\n\n:::\n\n```{.r .cell-code}\nseven_dwarfs_with_days |> \n  group_by(is_holiday) |> \n  summarise(mean_wait = mean(wait_minutes_posted_avg, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  is_holiday mean_wait\n  <lgl>          <dbl>\n1 FALSE           68.9\n2 TRUE            75.7\n```\n\n\n:::\n\n```{.r .cell-code}\nseven_dwarfs_with_days |> \n  count(is_weekend, park_extra_magic_morning)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  is_weekend park_extra_magic_morning     n\n  <lgl>                         <dbl> <int>\n1 FALSE                             0   198\n2 FALSE                             1    55\n3 TRUE                              0    96\n4 TRUE                              1     5\n```\n\n\n:::\n\n```{.r .cell-code}\nseven_dwarfs_with_days |> \n  group_by(is_weekend) |> \n  summarise(mean_wait = mean(wait_minutes_posted_avg, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  is_weekend mean_wait\n  <lgl>          <dbl>\n1 FALSE           69.6\n2 TRUE            68.0\n```\n\n\n:::\n:::\n\n\nNow, let's refit the IPW model including this expanded adjustment set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ipw_effect(\n  park_extra_magic_morning ~ park_temperature_high +\n    park_close + park_ticket_season + is_weekend + is_holiday,\n  .data = seven_dwarfs_with_days\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7.584\n```\n\n\n:::\n:::\n\n\nThe effect here is slightly bigger than what we got without the two new confounders. Scientifically, you most likely want to report *both* effects because in this case, it was a deviation from the analysis plan. That said, this new DAG is likely more correct than the original one. From a decision point of view, though, the difference is small in absolute terms and results in an effect in the same direction. In other words, the result is not terribly sensitive to this change in terms of how we might act on it.\n\nOne other point here: sometimes people present the results of using increasingly complicated adjustment sets. This comes from the tradition of trying to to compare complex models to parsimonious ones. This is a sort of sensitivity analysis in its own right, but it should be principled: rather than fitting models that are simple for simplicity's sake, you should compare *competing* adjustment sets or conditions. For instance, you may feel like these two DAGs are equally plausible, or you may want to examine if adding other variables better captures the baseline crowd flow at the Magic Kingdom. \n\n## Quantitative bias analyses\n\nThus far we've probed some of the assumptions we've made around the causal structure of the question. We can take this further using *quantitative bias analysis*, where we use mathematical assumptions to see how results would change under different conditions.\n\n### Tipping point analyses\n\n### Other types of QBA\n",
    "supporting": [
      "21-sensitivity_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}